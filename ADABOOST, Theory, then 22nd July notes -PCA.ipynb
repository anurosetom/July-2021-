{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "coordinated-warren",
   "metadata": {},
   "source": [
    "# ADA Boost - >Adaptive Gradient Boost \n",
    "## ADA Boost not using tree,its a forest of stumps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-reform",
   "metadata": {},
   "source": [
    "Main concepts:-\n",
    "    *Having Stumps ->ie, one node & 2 leaves only\n",
    "    *Stumps are weak learners, later combines all weak learners\n",
    "    *Some trees have more say /weightage,so based on high weightage we predict the preference\n",
    "    *Like a sequence \n",
    "    (if there is errors,it will pass to next node/tree,but it will have less weightage)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-steal",
   "metadata": {},
   "source": [
    "ADA Boost :-basically combines weak learners(called stumps) to make classifications\n",
    "    *each stump made by taking the previous stumps mistake into account(a sequence fashion)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-wright",
   "metadata": {},
   "source": [
    "stump 1 -its o/p weightage will be used for next stump"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-screen",
   "metadata": {},
   "source": [
    "root node is set based on Gini impurity\n",
    "stumps are created using features one by one\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-symposium",
   "metadata": {},
   "source": [
    "takes dataset\n",
    "added a new column sample weight(weightage)=1/8\n",
    "built tree(stump) for each features then:\n",
    "example:chest pain and Heart Disesase\n",
    "blocked arteries and HD\n",
    "    ...\n",
    "then takes weights as root node where weights are new ajacent avg weights\n",
    "    then built stump\n",
    "    root is wt>176\n",
    "    leaves are: Have HD(correct & incorrect options there) & No HD(correct & incorrect options there)\n",
    "    result will be like pure, 3 ,0 and 4,1\n",
    "            \n",
    "total error=sum of weights(incorrectly classified one)\n",
    "amount of say=1/2 log(1-total error)/total error\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-tractor",
   "metadata": {},
   "source": [
    "marking the misclassified data\n",
    "& reduce the weightage of correctly classified ones and increase for misclassfied one.\n",
    "then new column - new weights(scaled weights)\n",
    "its values are same for all correctly classified one:\n",
    "    value is high for misclassified data.\n",
    "    then:\n",
    "        1)normalize the column.\n",
    "        ie,add all new weights and reduce that total from each"
   ]
  },
  {
   "cell_type": "raw",
   "id": "detailed-habitat",
   "metadata": {},
   "source": [
    "#Gradident Boosting/regression theory notes:\n",
    "-leaf(avg of initial output value)\n",
    "-tree build\n",
    "-initial observations difference->residuals\n",
    "\n",
    "new tree using features+new residual\n",
    "..\n",
    "..\n",
    "finally reducing the residuals after each tree built one by one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-radar",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-arnold",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "executive-leonard",
   "metadata": {},
   "source": [
    "PCA - >Principle Component Analysis for dimensionality reduction\n",
    "\n",
    "# when axeses increases, until 3d is fine.\n",
    "\n",
    "# if morethan 4 d, it will group them by groups of 2 like:\n",
    "\n",
    "#                       PCA 1, PCA2, PCA 3 each with with 2 groups.\n",
    "\n",
    "# distance from origin need to increase\n",
    "\n",
    "# distance from fitted line need to decrease(residuals )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-owner",
   "metadata": {},
   "source": [
    "# distance from origin will be same, will not change\n",
    "\n",
    "ie, large dimenions of data, ie, 1000 dimension is there, inorder to draw each each graph, we can use PCA to handle them"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
